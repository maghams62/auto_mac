# Cerebro OS Configuration

# OpenAI API Configuration
openai:
  api_key: "${OPENAI_API_KEY}"  # Set in environment variable
  model: "gpt-4o"  # Highest generally available reasoning model
  embedding_model: "text-embedding-3-small"
  temperature: 0.2
  max_tokens: 2000

# VectorDB Configuration (Docs/Issues semantic search)
vectordb:
  enabled: true
  provider: "qdrant"  # Future-safe: can swap to pinecone/weaviate/etc.
  url: "${QDRANT_URL:-${VECTORDB_URL:-http://localhost:6333}}"
  api_key: "${QDRANT_API_KEY:-${VECTORDB_API_KEY:-}}"
  collection: "${QDRANT_COLLECTION:-${VECTORDB_COLLECTION:-oqoqo_context}}"
  embedding_model: "${VECTORDB_EMBEDDING_MODEL:-text-embedding-3-small}"
  default_top_k: 12
  min_score: 0.35
  timeout_seconds: 6.0
  dimension: 1536

mongo:
  enabled: false
  uri: "${MONGO_URI:-mongodb://127.0.0.1:27017}"
  database: "${MONGO_DB:-oqoqo}"
  chat_collection: "${MONGO_CHAT_COLLECTION:-chat_messages}"
  ttl_days: 30
  cache:
    max_messages_per_session: 75
    disk_path: "data/cache/chat_sessions"

# Graph / Neo4j Configuration
graph:
  enabled: false
  uri: "${NEO4J_URI:-bolt://localhost:7687}"
  username: "${NEO4J_USERNAME:-neo4j}"
  password: "${NEO4J_PASSWORD:-}"
  database: "${NEO4J_DATABASE:-neo4j}"
  ingest_batch_size: 100

activity_ingest:
  state_dir: "data/state/activity_ingest"
  slack:
    enabled: false
    batch_limit: 200
    workspace_url: ""  # Optional e.g., https://yourteam.slack.com
    dissatisfaction_keywords:
      - "fail"
      - "error"
      - "broken"
      - "down"
    negative_reactions:
      - "thumbsdown"
      - "rage"
      - "angry"
    channels:
      - id: "C0123456789"
        name: "#payments"
        components:
          - "comp:payments"
        endpoint_ids:
          - "api:payments:/charge"
        tags:
          - "payments"
        recency_half_life_hours: 72
        base_weight: 1.0
        dissatisfaction_keywords:
          - "timeout"
          - "failure"
  git:
    enabled: false
    default_branch: "main"
    lookback_hours: 168
    include_issues: true
    max_issues: 15
    issue_labels:
      - "bug"
      - "documentation"
    issue_dissatisfaction_labels:
      - "bug"
      - "docs"
      - "documentation"
    default_issue_components:
      - "comp:core"
    issue_component_map:
      - labels:
          - "documentation"
          - "docs"
        keywords:
          - "guide"
          - "tutorial"
        components:
          - "comp:docs"
      - labels:
          - "bug"
        components:
          - "comp:core"
    repos:
      - owner: "tiangolo"
        name: "fastapi"
        include_prs: true
        include_commits: true
        include_issues: true
        branch: "master"
        max_prs: 10
        max_commits: 20
        max_issues: 15
        default_components:
          - "comp:core"
        default_issue_components:
          - "comp:docs"
        component_map:
          - match: "docs/en/docs/"
            components:
              - "comp:docs"
          - match: "fastapi/routing"
            components:
              - "comp:core"
        issue_component_map:
          - labels:
              - "documentation"
              - "docs"
            components:
              - "comp:docs"
          - labels:
              - "bug"
            components:
              - "comp:core"

context_resolution:
  dependency_files:
    - "configs/dependency_map.yaml"
  repo_mode: "polyrepo"  # or "monorepo" to limit blast radius to each repo boundary
  activity_window_hours: 168
  impact:
    default_max_depth: 2
    include_docs: true
    include_services: true

# Reasoning Trace Configuration (Experimental)
# Enables persistent reasoning memory across agent executions
reasoning_trace:
  enabled: true  # EXPERIMENTAL: Enable reasoning trace (default: false for safety)
  # When enabled, the system tracks:
  # - Planning decisions and evidence
  # - Execution outcomes and artifacts
  # - Critic corrections and learnings
  # - Delivery commitments (e.g., send email, attach files)
  # This reduces reliance on prompt engineering by using actual execution history

# Delivery Intent Configuration (moved from hardcoded logic in agent.py)
delivery:
  # Intent detection verbs - when these appear in user request, plan must include compose_email
  intent_verbs:
    - email
    - send
    - mail
    - attach

  # Required tool when delivery intent is detected
  required_tool: compose_email

  # Validation behavior
  validation:
    reject_missing_tool: true  # Reject plan if delivery verb present but compose_email missing
    auto_correct: false  # Do not auto-add compose_email (let planner learn)

  # Map tools to commitments they fulfill (used by reasoning trace)
  tool_commitments:
    compose_email:
      - send_email

# Atomic Prompt Loading Configuration
atomic_prompts:
  enabled: true  # Enable atomic prompt loading (default: true)
  max_tokens: 2000  # Maximum tokens to allocate for examples per request
  fallback_to_full: true  # Fallback to full examples if atomic loading fails
  log_usage: true  # Log token usage and example selection

document_directory: "/Users/siddharthsuresh/Downloads/auto_mac/tests/data/test_docs"

# Screenshot Configuration
screenshots:
  base_dir: "data/screenshots"

# Playback Configuration
playback:
  # Intent detection verbs for Spotify playback requests
  intent_verbs:
    - play
    - queue
    - listen
    - start

  # Tool that must appear in plans when playback intent detected
  required_tool: play_song

  # Verification tool to confirm playback before responding
  verification_tool: get_spotify_status
  require_status_check: true

  # Force API-based playback for Spotify (no vision automation)
  use_api: true

  # Disable fallback to automation when API is not available
  # When true, playback will only work through web API (requires authentication)
  disable_automation_fallback: true

  # Retry configuration for playback automation (consumed by routers)
  retry:
    max_attempts: 3
    base_delay_seconds: 2

  # Commitments produced by specific tools
  tool_commitments:
    play_song:
      - play_music

  # Messaging used during finalization
  success_message: "Started playback in Spotify."
  failure_message: "Unable to confirm Spotify playback. Please ensure Spotify is running and try again."

# Document Configuration
documents:
  # Folders to index (can add multiple paths)
  folders:
    - "/Users/siddharthsuresh/Downloads/auto_mac/tests/data/test_docs"


  # File types to index
  supported_types:
    - ".pdf"
    - ".docx"
    - ".txt"

  # Image types to index
  supported_image_types:
    - ".jpg"
    - ".jpeg"
    - ".png"
    - ".gif"
    - ".webp"

  # Index refresh interval (in seconds, -1 to disable auto-refresh)
  refresh_interval: 3600

# Search Configuration
search:
  # Number of top results to return
  top_k: 5

  # Similarity threshold (0-1, higher = more strict)
  similarity_threshold: 0.45

# Images Configuration
images:
  # Enable/disable image indexing and search
  enabled: true

  # Caption generation model (for MVP, we'll use a simple approach)
  caption_model: "blip-base"  # Options: blip-base, blip-large, or openai-vision

  # Embedding model for semantic search
  embedding_model: "clip-vit-base-patch32"  # CLIP model for vision-text alignment

  # Thumbnail settings
  thumbnail:
    max_size: 256  # Maximum thumbnail dimension in pixels
    quality: 85    # JPEG quality (1-100)
    cache_dir: "data/cache/thumbnails"

  # Search settings
  search:
    top_k: 5  # Number of image results to return

# Universal Search Configuration
universal_search:
  # Enable/disable the Command-K universal search feature
  enabled: true

  # Maximum results to return (default: 10)
  max_results: 10

  # Frontend debounce delay in milliseconds (default: 200)
  debounce_ms: 200

  # Maximum characters in snippet context (default: 150)
  highlight_context: 150

  # Security settings
  security:
    # Rate limit per second per client
    rate_limit_per_second: 10
    # Only return results from allowed directories
    allowed_paths_only: true

# Email Configuration
email:
  account_email: "Google"  # YOUR email ACCOUNT NAME in Mail.app (not email address) - used for READING emails (SECURITY: only reads from this account)
  default_recipient: "spamstuff062@gmail.com"  # Default email address when user says "email to me"
  default_subject_prefix: "[Auto-generated]"
  signature: "\n\n---\nSent via Cerebro OS"

# iMessage Configuration
imessage:
  default_phone_number: "+16618572957"  # Default recipient for messages

# Discord Configuration
discord:
  default_server: "Personal"        # Default server for quick navigation (optional)
  default_channel: "general"        # Default channel fallback
  screenshot_dir: "data/screenshots"
  switcher_delay_seconds: 0.6       # Delay between Cmd+K keystrokes
  credentials:
    email: "${DISCORD_EMAIL}"
    password: "${DISCORD_PASSWORD}"
    mfa_code: "${DISCORD_MFA_CODE}"

# Reddit Configuration
reddit:
  headless: true
  default_sort: "hot"
  max_scroll_iterations: 12
  scroll_pause_ms: 1200
  comment_threads_limit: 3
  viewport:
    width: 1280
    height: 900
  user_agent: "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"

# Maps Configuration
maps:
  max_stops: 20  # Maximum total stops (fuel + food combined) - can be increased if needed
  default_maps_service: "google"  # "apple" or "google" - which Maps service to use by default (LLM can override based on user query)
  stop_suggestion_max_tokens: 1000  # Max tokens for LLM stop suggestion (increased for international routes)

  # Google Maps API configuration
  google_maps_api_key: "${GOOGLE_MAPS_API_KEY}"  # Set in environment variable

# UI Configuration
ui:
  mode: "terminal"  # Options: terminal, gui (future)
  theme: "dark"
  # Redirect URL configuration
  # Note: Spotify requires 127.0.0.1 (loopback) for HTTP redirects, not localhost
  redirect_url: "${REDIRECT_URL:-http://127.0.0.1:3000/redirect}"  # Default redirect URL for OAuth callbacks

# OAuth Configuration
oauth:
  # Base redirect URL (used for OAuth callbacks)
  # Note: Spotify requires 127.0.0.1 (loopback) for HTTP redirects, not localhost
  redirect_base_url: "${REDIRECT_BASE_URL:-http://127.0.0.1:3000}"
  redirect_path: "/redirect"  # Path component of redirect URL
  # Allowed redirect destinations (for security)
  allowed_redirect_domains:
    - "localhost"
    - "127.0.0.1"
    # Add your production domain here when deploying

# Spotify API Configuration
spotify_api:
  # OAuth credentials (set via environment variables)
  client_id: "${SPOTIFY_CLIENT_ID}"
  client_secret: "${SPOTIFY_CLIENT_SECRET}"
  # Redirect URI for Spotify OAuth (must match Spotify Developer Dashboard)
  # Use 127.0.0.1 (loopback) for local development - Spotify requires this format for HTTP
  redirect_uri: "${SPOTIFY_REDIRECT_URI:-http://127.0.0.1:3000/redirect}"
  # Scopes required for Spotify API access
  scopes:
    - "user-read-playback-state"
    - "user-modify-playback-state"
    - "user-read-currently-playing"
    - "streaming"
    - "user-read-email"
    - "user-read-private"

# Browser/Web Configuration
browser:
  # Whitelist of allowed websites for web scraping/browsing
  # Only these domains can be accessed by browser automation tools
  allowed_domains:
    # Financial data sources
    - "finance.yahoo.com"
    - "yahoo.com"
    - "bloomberg.com"
    - "marketwatch.com"
    - "cnbc.com"
    - "investing.com"
    - "seekingalpha.com"
    - "fool.com"
    - "morningstar.com"
    - "finviz.com"
    # Add more finance-related domains as needed

  # Maximum page load timeout (milliseconds)
  timeout: 30000

  # Run browser in headless mode
  headless: true

  # When true, every Google search uses a fresh Playwright profile to avoid CAPTCHAs
  unique_session_search: true

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "data/app.log"
  max_bytes: 10485760  # 10MB - max size before rotation
  backup_count: 5  # Number of backup log files to keep
  json_format: true  # Use JSON format for structured logging (true) or human-readable (false)

# Retry Logging Configuration (Experimental)
# Enables comprehensive logging of failed attempts and reasoning chains for recovery
retry_logging:
  enabled: true  # EXPERIMENTAL: Enable retry logging (default: true for better error recovery)
  # When enabled, the system tracks:
  # - Failed execution attempts with full context
  # - Reasoning chains that led to failures
  # - Critic feedback and suggested fixes
  # - Recovery patterns and alternative approaches
  # This enables smarter retries and better LLM handoffs

  # Retry behavior settings
  max_attempts: 3  # Maximum retry attempts per operation
  base_delay_seconds: 1.0  # Base delay between retries
  max_delay_seconds: 30.0  # Maximum delay cap
  backoff_multiplier: 2.0  # Exponential backoff multiplier

  # Logging settings
  log_directory: "data/retry_logs"  # Directory for retry logs
  max_logs_per_interaction: 10  # Maximum log files per interaction
  compress_old_logs: true  # Compress logs older than retention period
  retention_days: 7  # Days to keep retry logs

# Twitter Configuration
twitter:
  default_list: "product_watch"        # Logical name defined in lists mapping below
  default_lookback_hours: 24           # Used when user does not specify a window
  max_summary_items: 5                 # Maximum tweets/threads to summarize per run
  lists:
    # Map logical names to actual Twitter List IDs (replace with your own)
    product_watch: "72719839"

# Bluesky Configuration
bluesky:
  default_lookback_hours: 24           # Used when summarizing posts without explicit timeframe
  max_summary_items: 5                 # Maximum posts to summarize
  default_search_limit: 10             # Default number of posts to return for search
  default_query: ""                    # Optional fallback query when none provided (leave empty to require explicit query)

  # Notification Service Configuration
  notifications_enabled: true          # Enable/disable real-time notifications
  notification_poll_interval_seconds: 60  # How often to poll for new notifications (30-300 recommended)
  max_notifications_per_poll: 20       # Maximum notifications to fetch per poll cycle
  enable_timeline_mentions: true       # Monitor timeline for @mentions (may increase API usage)
  enable_notifications: true           # Monitor official notifications (mentions, replies, likes, follows)

# Voice Configuration
voice:
  default_voice: "alloy"               # Default TTS voice: alloy, echo, fable, onyx, nova, shimmer
  default_speed: 1.0                   # Default speech speed (0.25 to 4.0)
  tts_model: "tts-1"                   # TTS model: "tts-1" (faster) or "tts-1-hd" (higher quality)
  stt_model: "whisper-1"               # Speech-to-text model (Whisper)
  audio_output_dir: "data/audio"       # Directory for generated audio files

# WhatsApp Configuration
whatsapp:
  screenshot_dir: "data/screenshots"   # Directory for WhatsApp screenshots

# Weather Configuration
weather:
  default_location: "San Francisco, CA"  # Default location for weather queries

# Notes Configuration
notes:
  default_folder: "Notes"  # Default folder for creating notes

# Reminders Configuration
reminders:
  default_list: "Reminders"  # Default list for creating reminders

# Vision-Assisted UI Navigation
vision:
  enabled: false                       # Enable vision-based fallback path
  min_confidence: 0.65                 # Confidence needed before using vision
  max_calls_per_session: 5             # Limit per session to control cost
  max_calls_per_task: 2                # Limit per automation run
  retry_threshold: 2                   # Escalate after N scripted failures
  eligible_tools:                      # Tools allowed to route through vision path
    - open_maps_with_route
    - plan_trip_with_stops
    - launch_app
    - send_whatsapp_message

# Writing Agent Configuration
writing:
  # Refinement settings
  max_refinement_passes: 2              # Maximum Self-Refine passes per deliverable
  max_refinement_tokens: 2000           # Token guardrail for refinement operations

  # Style profiles and defaults
  default_tones:
    executive: "professional, strategic, high-level"
    technical: "precise, detailed, accurate"
    conversational: "friendly, clear, approachable"
    formal: "structured, comprehensive, authoritative"

  # Slide deck constraints
  slide_limits:
    default: 5                         # Default maximum slides
    max_with_justification: 7          # Maximum when memory indicates broader scope

  # Quality assurance thresholds
  rubric_thresholds:
    email: 0.75                        # Minimum score for email approval
    report: 0.8                        # Minimum score for report approval
    summary: 0.7                       # Minimum score for summary approval
    presentation: 0.75                 # Minimum score for presentation approval

  # Chain-of-Density settings
  quality_chain_density_score: 0.7     # Target density score for CoD summarization

# Persistent User Memory Configuration
# Enables long-term memory across sessions with semantic search
persistent_memory:
  enabled: true  # Enable persistent memory (default: false for privacy)
  directory: "data/user_memory"  # Storage directory for user memory data
  embedding_model: "text-embedding-3-small"  # OpenAI embedding model
  retention:
    max_memories_per_user: 1000  # Maximum memories per user
    default_ttl_days: 365  # Default time-to-live for memories (days)
    cleanup_interval_days: 30  # How often to clean up expired memories
  extraction:
    similarity_threshold: 0.87  # Cosine similarity threshold for deduplication
    min_confidence: 0.7  # Minimum confidence to store extracted memories
    max_per_interaction: 3  # Maximum memories to extract per interaction
  search:
    top_k_default: 5  # Default number of memories to retrieve
    min_score_default: 0.7  # Default minimum similarity score

# Knowledge Providers Configuration
# Enables external knowledge sources for factual information retrieval
knowledge_providers:
  enabled: true  # Enable knowledge providers (default: true)
  wiki_lookup:
    enabled: true  # Enable Wikipedia lookup (default: true)
    cache_dir: "data/cache/knowledge"  # Directory for caching knowledge responses
    cache_ttl_hours: 24  # Cache time-to-live in hours
    timeout_seconds: 10  # Request timeout for external API calls
    max_retries: 2  # Maximum retry attempts for failed requests

# Performance Optimization Configuration
performance:
  # HTTP Connection Pooling (20-40% faster requests)
  connection_pooling:
    enabled: true
    max_connections: 100  # Maximum total connections
    max_keepalive: 50     # Maximum keep-alive connections
    keepalive_expiry: 30  # Keep-alive timeout in seconds
  
  # Rate Limiting (prevents API throttling)
  rate_limiting:
    enabled: true
    rpm_limit: 10000      # Requests per minute
    tpm_limit: 2000000    # Tokens per minute
    burst_size: 100       # Allow request bursts
    safety_margin: 0.9    # Use 90% of limits
  
  # Parallel Execution (40-60% faster overall)
  parallel_execution:
    enabled: true
    max_parallel_steps: 5          # Maximum concurrent steps
    max_parallel_llm_calls: 3      # Maximum concurrent LLM calls
    dependency_analysis: true      # Analyze step dependencies
  
  # Batch Processing (30-50% faster embeddings)
  batch_embeddings:
    enabled: true
    batch_size: 100               # Documents per batch
    max_concurrent_batches: 2     # Concurrent batch requests
  
  # Caching (instant responses for repeated queries)
  caching:
    tool_catalog: true            # Cache tool catalog
    prompt_templates: true        # Cache prompt templates
    embeddings: true              # Cache embeddings (if persistent)
  
  # Background Processing
  background_tasks:
    verification: true            # Run verification in background
    memory_updates: true          # Update memory asynchronously
    logging: true                 # Async logging

# Slack Configuration
slack:
  bot_token: "${SLACK_BOT_TOKEN}"          # Slack Bot Token (xoxb-...)
  default_channel_id: "${SLACK_CHANNEL_ID}" # Default channel ID for fetching messages

  # Monitored channels for search (channel IDs)
  # Example: ["C0123456789", "C9876543210"]
  monitored_channels: []

  # Search settings
  search:
    default_limit: 20    # Default number of messages to return
    max_limit: 100       # Maximum messages per search request

# Slash-Slack agent configuration
slash_slack:
  default_channel_id: ""            # Optional override if different from slack.default_channel_id
  default_time_window_hours: 24     # Default lookback window for channel recaps
  workspace_url: ""                 # e.g., https://yourteam.slack.com for permalink construction
  graph_emit: true                  # Emit graph payloads for Neo4j ingestion hooks
  graph_log_path: "data/logs/slash/slack_graph.jsonl"
  empty_channel_fallback_hours: 72  # When no messages match, extend the lookback window (hours)
  empty_channel_search_limit: 40    # Max messages to retrieve via Slack search fallback
  doc_drift_keywords:               # Only run doc drift reasoner when these keywords appear
    - "doc drift"
    - "drift"
    - "api drift"
  debug_block_enabled: ${SLASH_SLACK_DEBUG_BLOCK_ENABLED:-true}
  debug_source_label: "${SLASH_SLACK_DEBUG_SOURCE_LABEL:-synthetic_slack}"

slash_git:
  doc_drift_reasoner: true
  debug_block_enabled: ${SLASH_GIT_DEBUG_BLOCK_ENABLED:-true}
  debug_source_label: "${SLASH_GIT_DEBUG_SOURCE_LABEL:-synthetic_git}"
  debug_repo_label: "${SLASH_GIT_DEBUG_REPO_LABEL:-${GITHUB_REPO_NAME:-auto_mac}}"

# Activity Intelligence / Oqoqo
activity:
  oqoqo:
    api_key: "${OQOQO_API_KEY:-}"               # API key for multi-source reasoning backend
    base_url: "${OQOQO_BASE_URL:-https://api.oqoqo.ai}"
    dataset: "${OQOQO_DATASET:-production}"     # Workspace or dataset slug

# GitHub Integration (Oqoqo Self-Evolving Docs + Git Agent)
# Used for PR/branch-based API documentation drift detection and Git agent tools
github:
  token: "${GITHUB_TOKEN}"              # GitHub Personal Access Token
  repo_owner: "${GITHUB_REPO_OWNER:-maghams62}"   # Repository owner
  repo_name: "${GITHUB_REPO_NAME:-auto_mac}"      # Repository name
  monitored_file: "api_server.py"       # File to monitor for API changes
  base_branch: "${GITHUB_BASE_BRANCH:-main}"      # Base branch to compare against

  # PR webhook filtering
  webhook:
    enabled: true                       # Enable webhook event processing
    filter_by_branch: true              # Only process PRs targeting base_branch

  # PR notification actions to handle
  notification_actions:
    - opened                            # New PR opened
    - ready_for_review                  # PR marked ready for review
    - closed                            # PR closed or merged
    - synchronize                       # PR updated with new commits
    - reopened                          # PR reopened

branch_watcher:
  enabled: true
  startup_delay_seconds: 8              # Delay before starting GitHub polling (seconds)

synthetic_git:
  base_dir: "data/synthetic_git"
  branch: "${SYNTHETIC_GIT_BRANCH:-synthetic-git-dataset}"
  base_branch: "${SYNTHETIC_GIT_BASE_BRANCH:-main}"
  remote_url: "${SYNTHETIC_GIT_REMOTE:-}"
  repo_owner: "${SYNTHETIC_GIT_REPO_OWNER:-maghams62}"
  repo_name: "${SYNTHETIC_GIT_REPO_NAME:-auto_mac}"
  commit_message: "chore(synthetic-git): refresh dataset"
