# Runtime Modes & Ingest (working draft)

This document tracks the implementation of the "Unified Ingest then View" workflow.  
It will grow as we wire the runtime mode switch (`CEREBROS_MODE`) into every ingest + dashboard surface.

---

## 1. Current ingest + index inventory

| Flow | Entry point(s) | Source(s) | Sink(s) / artifacts | Key config & env toggles |
| --- | --- | --- | --- | --- |
| Slack activity ingest | `scripts/run_activity_ingestion.py --sources slack`<br>`SlackActivityIngestor` (`src/ingestion/slack_activity_ingestor.py`) | Slack Web API via `SlackAPIClient` (channel history)<br>Fixture loader: `SlackActivityIngestor.ingest_fixture_messages()` reads `data/synthetic_slack/*.json`. | - Neo4j via `GraphIngestor` (`activity_signals`, `slack_event`, `slack_thread` nodes)<br>- Qdrant (vector chunks) through `get_vector_search_service()`<br>- Signal log: `data/logs/slash/slack_graph.jsonl`<br>- Cursor/state: `data/state/activity_ingest/slack_<channel>.json` | `activity_ingest.slack.enabled`, channel list, component tags, keywords, `batch_limit`<br>`SLACK_BOT_TOKEN`, `SLACK_WORKSPACE_URL` envs for live mode<br>Requires `NEO4J_ENABLED=true` for graph writes; obeys vectordb settings<br>Fixtures accessible when `ENABLE_TEST_FIXTURE_ENDPOINTS=1`. |
| Git activity ingest | `scripts/run_activity_ingestion.py --sources git`<br>`GitActivityIngestor` (`src/ingestion/git_activity_ingestor.py`) | GitHub REST API via `GitHubPRService` for PRs/commits/issues (per repo config)<br>Fixture loader: `GitActivityIngestor.ingest_fixtures()` consumes `data/synthetic_git/*.json`. | - Neo4j via `GraphIngestor` (`pr`, `git_event`, `issue`, `activity_signal`, `support_case` nodes)<br>- Qdrant via `get_vector_search_service()` (PR/commit/issue chunks)<br>- Signal log: `data/logs/slash/git_graph.jsonl`<br>- Cursor/state: `data/state/activity_ingest/git_<repo>.json` | `activity_ingest.git.enabled`, repo list (owner/name/branch/scopes), lookback hours, `include_prs/commits/issues`<br>`GITHUB_TOKEN` (or repo-level overrides) + `SLASH_GIT_USE_LIVE_DATA`<br>`NEO4J_ENABLED`, vectordb config, `IMPACT_DATA_MODE` (issue weighting)<br>Fixtures gated by `ENABLE_TEST_FIXTURE_ENDPOINTS`. |
| Doc issue ingest | `scripts/run_activity_ingestion.py --sources doc_issues`<br>`DocIssueIngestor` (`src/ingestion/doc_issue_ingestor.py`) | JSON artifacts generated by Impact pipeline (default `data/live/doc_issues.json`). | Neo4j issues/support cases linked to components/APIs; uses `GraphIngestor`. | `activity_ingest.doc_issues.enabled`, `activity_ingest.doc_issues.path`, `default_component` fallback<br>`DOC_ISSUES_PATH` (and `ACTIVITY_GRAPH_DOC_ISSUES_PATH`) override the shared file used by ingest + search<br>Requires `impact.data_mode` to have produced the doc issue file; honors `NEO4J_ENABLED`. |
| Impact auto ingest (doc issues builder) | `scripts/impact_auto_ingest.py` (used directly & by `scripts/refresh_live_ingest.py`) | Git repos discovered from `activity_ingest.git.repos`; Impact pipeline fetches commits via GitHub + dependency graph. | - Writes new doc-issue JSON records (impact reports) into `data/live/doc_issues.jsonl/json` via `ImpactService`<br>- Updates state: `data/state/impact_auto_ingest.json` (per-repo cursors). | `impact.data_mode` (live vs synthetic). Script refuses to run when `impact.data_mode=synthetic` unless `--allow-synthetic`.<br>Requires same GitHub creds as git ingest, plus OpenAI/Qdrant/Neo4j depending on configured pipeline tools. |
| Synthetic graph builder | `scripts/ingest_synthetic_graph.py` → `SyntheticGraphIngester` | Fixture bundles under `data/synthetic_git/*`, `data/synthetic_slack/*`, `config/canonical_ids.yaml`, etc. | Populates Neo4j (services/components/APIs/docs/git/slack) without touching live APIs. | `NEO4J_ENABLED` must be true for writes; typically paired with `CEREBROS_MODE=dev/demo` and `ENABLE_TEST_FIXTURE_ENDPOINTS=1`. |
| Synthetic event → Neo4j/vector utilities | `scripts/ingest_events_to_neo4j.py`<br>`scripts/ingest_events_to_vector.py` | `activity_ingest.events_loader.load_all_events()` reading `data/synthetic_slack/slack_events.json` + `data/synthetic_git/git_events.json`. | - Direct Neo4j writes via bolt driver (`Event`, `Component`, `Service`, `APIEndpoint` nodes).<br>- Manual Qdrant upserts (custom embeddings). | Point-in-time tooling for demos/tests; controlled by CLI flags for file paths, `NEO4J_URI`, `QDRANT_URL`, etc. |
| Aggregated live refresh | `scripts/refresh_live_ingest.py` | Delegates to `scripts/check_live_env.py`, `scripts/run_activity_ingestion.py`, `scripts/impact_auto_ingest.py`. | Same sinks as underlying commands. | Flags `--skip-slack`, `--skip-git`, `--skip-impact`, `--limit`. Ensures env parity between backend & dashboard. |

> **Notes**
> - All graph writes depend on `GraphService`, which is disabled unless `NEO4J_ENABLED=true` (set explicitly or via `CEREBROS_MODE=live`).
> - Vector indexing paths respect `vectordb.*` config and will no-op when the client is unavailable (common in `dev/demo`).
> - Fixture ingestion helpers exist for both Slack and Git so demos can avoid live APIs while still exercising the pipelines.
> - Cursor/state files live under `data/state/*`; these need to be reset or separated when switching between demo and live datasets.

---

## 2. Mode-aware ingest contract

The runtime mode switch now drives the ingest scripts directly, so `dev`, `demo`, and `live` behave predictably without extra flags.

| Mode | Slack ingest | Git ingest | Doc issues / Impact | Notes |
| --- | --- | --- | --- | --- |
| `live` | Hits Slack Web API (requires `SLACK_BOT_TOKEN`). | Hits GitHub via `GitHubPRService` (requires GitHub token). | `impact_auto_ingest.py` allowed (since `IMPACT_DATA_MODE` defaults to `live`). `DocIssueIngestor` reads whatever the Impact pipeline produced. | Set by `CEREBROS_MODE=live` or `runtime.mode: live`. |
| `dev` / `demo` | Defaults to fixtures when `activity_ingest.slack.fixture_path` is set (YAML/JSON). Logs the number of messages ingested. If no fixture path, skips quietly. | Defaults to fixture ingestion (`activity_ingest.git.fixture_path`) and writes to Neo4j/Qdrant just like live ingest. If file missing, skips. | Impact auto-ingest is blocked because `IMPACT_DATA_MODE` defaults to `synthetic`; you can still run it with `--allow-synthetic` if needed. | `ENABLE_TEST_FIXTURE_ENDPOINTS=1` ensures fixture-backed endpoints stay available. |

### Script semantics implemented in `scripts/run_activity_ingestion.py`

- `--sources` now accepts either `--sources slack git` or `--sources slack,git`.
- `--force-live` bypasses the runtime-mode guard so you can hit live APIs while staying in `CEREBROS_MODE=dev` for everything else.
- `--fixture-repo-id` controls the repo label used when loading git fixtures (default `fixtures:activity`).
- Fixture paths are configurable via:

```yaml
activity_ingest:
  slack:
    fixture_path: "tests/fixtures/activity/slack_activity.yaml"
  git:
    fixture_path: "tests/fixtures/activity/git_activity.yaml"
```

You can point these at any YAML/JSON payload that matches the existing test fixtures. When the files are absent (or empty), the ingest command simply logs that it skipped fixtures in dev/demo mode.

---

## 3. Friendly CLI entrypoints

Run the new helper to kick off ingestion without remembering long commands:

```bash
# Refresh everything (Slack + Git + doc issues) respecting CEREBROS_MODE
python scripts/cerebros.py ingest all

# Slack-only ingest in demo mode (uses fixtures automatically)
python scripts/cerebros.py ingest slack

# Full live ingest plus doc-issue refresh
CEREBROS_MODE=live python scripts/cerebros.py ingest git --with-impact

# Force live APIs even while staying in dev mode
CEREBROS_MODE=dev python scripts/cerebros.py ingest all --force-live
```

- The CLI simply wraps `scripts/run_activity_ingestion.py` (for Slack/Git/doc issues) and optionally `scripts/impact_auto_ingest.py` (`--with-impact`).
- `--impact-limit` and `--impact-allow-synthetic` are forwarded to the Impact auto-ingestor for finer control.
- All commands run from the repo root so your current `CEREBROS_MODE` (and other env vars) automatically apply.

### Fixture seeding & status checks

- `python scripts/seed_activity_graph.py` runs the Slack + Git + doc issue fixture pipelines (and the Impact auto-ingestor with `--allow-synthetic`) in one shot so `/cerebros` always has signals to reason about. Pass `--skip-impact` if you only need ActivitySignal nodes.
- `python scripts/seed_incident_scenarios.py` rewrites the curated fixture set (`tests/fixtures/activity/*.yaml`) and the synthetic JSON bundles under `data/synthetic_slack/` + `data/synthetic_git/`. The script emits four high-signal scenarios (high activity, high dissatisfaction, cross-system break, doc drift) and accepts `--ingest`, `--ingest-target {all|slack|git}`, and `--with-impact` flags to immediately call `python scripts/cerebros.py ingest ...` after writing the files. This keeps the Activity Graph, Neo4j, and the dashboard in sync without manually editing sample payloads.
- Any time you tweak the synthetic Slack/Git fixtures, rerun `seed_incident_scenarios.py` so both the YAML fixtures **and** the `data/synthetic_*/*.json` bundles stay aligned before you kick off `python scripts/cerebros.py ingest ...`.
- `python scripts/cerebros.py status activity-graph` inspects the three primary artifacts (Slack JSONL, Git JSONL, doc_issues JSON) and prints counts + the latest timestamps/components so you can confirm the seed worked before running queries.
- Both commands honor the same environment variables as the underlying pipelines, so ensure `NEO4J_ENABLED=true` and your fixture paths exist.

---

## 4. Dashboard alignment & ingest metadata

- New FastAPI endpoint `GET /api/ingest/status` inspects `data/state/activity_ingest/*` and `data/state/impact_auto_ingest.json` so every modality (Slack, Git, doc issues) reports:
  - Current mode (`live` vs `synthetic`, derived from `CEREBROS_MODE` + `impact.data_mode`).
  - Last successful timestamps per channel/repo, plus doc-issues file freshness.
  - Health state (`ok`, `stale`, `idle`, or `disabled`).
- The Next.js app exposes `/api/ingest-status`, which proxies the backend endpoint and wraps it in the shared API envelope so dependency logging continues to work.
- `AppShell` now renders an **IngestStatusWidget** beside the existing live-mode badge. It polls once per minute and shows:
  - Source badge (Slack/Git/Doc issues) with mode label and “Updated X min ago” timestamp pulled straight from the backend.
  - Clear degraded messaging when a source is stale or idle, so you immediately know if you need to run `cerebros ingest ...`.

This keeps the dashboard honest: every visual (Brain Universe, activity monitors, doc issues) now advertises the freshness of the exact stores that the ingest commands populate.

---

## 5. Live vs. demo playbooks

### Live data refresh

1. `export CEREBROS_MODE=live` so Slack/Git/Impact run against real services.
2. Make your change (Slack message, Git commit/PR, etc.).
3. Run the all-in-one ingest:
   ```bash
   python scripts/cerebros.py ingest all --with-impact
   ```
   - `--with-impact` runs `impact_auto_ingest.py` after Slack/Git finish so doc issues stay in sync.
   - Add `--force-live` only if you explicitly want to bypass runtime safeguards (for example, forcing live ingest while leaving the rest of the stack in demo mode).
4. Watch `/api/ingest/status` (or the new header widget) flip to “Live / Updated <n> min ago”.
5. Refresh the dashboard / Brain Universe. All widgets now read from the same Neo4j + Qdrant datasets the ingest commands just updated.

### Demo / fast fixture refresh

1. `export CEREBROS_MODE=demo` (or `dev`) — this flips Slack/Git ingestion to the configured fixture files.
2. Optionally edit `activity_ingest.slack.fixture_path` / `activity_ingest.git.fixture_path` to point at your curated sample dataset.
3. Run whichever pipelines you want to “freeze” into the demo:
   ```bash
   python scripts/cerebros.py ingest slack         # only Slack fixtures
   python scripts/cerebros.py ingest git           # git fixtures (neo4j + qdrant)
   python scripts/cerebros.py ingest all           # slack + git + doc issues from files
   ```
4. The dashboard header will label each source as “Synthetic” and show the exact fixture timestamp (helpful during demos so you can say “dataset updated 5 min ago”).
5. Switch back to `CEREBROS_MODE=live` whenever you need real signals; no other config changes are required.

Troubleshooting checklist:

- If `/api/ingest/status` reports `idle` for a modality, re-run `python scripts/cerebros.py ingest ...`.
- If the status stays `stale`, verify credentials (Slack bot token, GitHub token, Neo4j/Qdrant connectivity).
- Use `--fixture-repo-id` to label synthetic git activity (default `fixtures:activity`) so you can distinguish it in Neo4j debugging views.
- When `/cerebros summarize ...` returns “No evidence found”, the fastest fix is to run `python scripts/seed_activity_graph.py` followed by `python scripts/cerebros.py status activity-graph` to double-check each modality has recent entries.

---

## 6. Dashboard + slash demo tips

- The Cerebros chat UI launched via `MASTER_PORT=3300 bash master_start.sh` binds to port **3300** (backend still uses 8000). The dashboard launcher (`cd oqoqo-dashboard && ./oq_start.sh`) now defaults to **3100** and errors if that port is busy so you can intentionally pick another (`PORT=<alt> ./oq_start.sh`).
- Need both surfaces remotely? Forward ports 3100 (dashboard) and 3300 (Cerebros) plus 8000 if you want to curl FastAPI directly: `ssh -L 3100:localhost:3100 -L 3300:localhost:3300 -L 8000:localhost:8000 <host>`.
- Need to generate a fresh incident for a demo? Use the helper script:

```bash
source venv/bin/activate
python scripts/demo_slash_to_dashboard.py \
  --query "Which docs need to be updated first after the VAT rollout?" \
  --component-id docs.payments \
  --dashboard-port 3100
```

This will:

1. Call `POST /api/graph/query` with your prompt/component hints.
2. Promote the returned `incident_candidate` via `POST /api/incidents`.
3. Print the incident ID, Brain trace link, and the ready-to-open dashboard URL (`http://localhost:<port>/incidents/<id>`).

Because the dashboard API routes (`/api/cerebros/*`, `/api/incidents/*`) live on whichever port the Next.js server is using, remember to curl the **dashboard port** (3100 by default). Directly hitting `http://localhost:3300/api/...` will talk to the Cerebros chat app instead and return a 404.

